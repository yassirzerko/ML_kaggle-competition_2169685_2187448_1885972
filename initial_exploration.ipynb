{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DblFtrBCMJQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "\n"
      ],
      "metadata": {
        "id": "5kJ5wJw9OXLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10b76ae-1cbc-4338-99f0-0e51e60b2964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "IlawQ1QhPd_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial data exploration and removing empty rows"
      ],
      "metadata": {
        "id": "G1YGp_JfX1bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_frames() :\n",
        "  data = pd.read_csv('train.csv')\n",
        "  data_to_predict = pd.read_csv('test.csv')\n",
        "  return (data, data_to_predict)\n",
        "\n",
        "def clean_data(data, is_data_to_predict) :\n",
        "  columns_to_drop = ['Id']#, 'Concert ID', 'Concert Goer ID']\n",
        "  Ids = data['Id']\n",
        "  data = data.drop(columns=columns_to_drop)\n",
        "  if not is_data_to_predict : \n",
        "      data = data.dropna()\n",
        "  return data, Ids\n",
        "\n",
        "def get_X_y(data) :\n",
        "  target_variable = 'Concert Enjoyment'\n",
        "  X = data.drop(columns = [target_variable])\n",
        "  y = data[target_variable]\n",
        "\n",
        "  return X,y\n"
      ],
      "metadata": {
        "id": "Yu1aqtxEMQS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = get_data_frames()\n",
        "na_rows = train_data.isna().any(axis=1)\n",
        "number_of_invalid_row = np.sum(na_rows)\n",
        "number_of_row = len(train_data)\n",
        "\n",
        "print('% of invalid lines', (number_of_invalid_row/ number_of_row) * 100, ' %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zplYNzgmTMSq",
        "outputId": "c0b4b8fc-c0ba-46f5-eaf6-56173837065d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of invalid lines 8.221764705882354  %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()\n",
        "print(train_data['Rain'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXSk1JvEWK4g",
        "outputId": "8bee0e46-104f-4d76-b0c8-774f52497f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 170000 entries, 0 to 169999\n",
            "Data columns (total 19 columns):\n",
            " #   Column                          Non-Null Count   Dtype  \n",
            "---  ------                          --------------   -----  \n",
            " 0   Id                              170000 non-null  object \n",
            " 1   Band Name                       169141 non-null  object \n",
            " 2   Band Genre                      169116 non-null  object \n",
            " 3   Band Country of Origin          169210 non-null  object \n",
            " 4   Band Debut                      169143 non-null  float64\n",
            " 5   Concert ID                      169130 non-null  float64\n",
            " 6   Concert Attendance              169105 non-null  float64\n",
            " 7   Inside Venue                    169162 non-null  object \n",
            " 8   Rain                            169139 non-null  object \n",
            " 9   Seated                          169168 non-null  object \n",
            " 10  Personnality Trait 1            169148 non-null  float64\n",
            " 11  Personnality Trait 2            169151 non-null  float64\n",
            " 12  Personnality Trait 3            169107 non-null  float64\n",
            " 13  Personnality Trait 4            169135 non-null  float64\n",
            " 14  Concert Goer Age                169147 non-null  float64\n",
            " 15  Concert Goer ID                 169185 non-null  object \n",
            " 16  Height (cm)                     169153 non-null  float64\n",
            " 17  Concert Goer Country of Origin  169141 non-null  object \n",
            " 18  Concert Enjoyment               170000 non-null  object \n",
            "dtypes: float64(9), object(10)\n",
            "memory usage: 24.6+ MB\n",
            "0         False\n",
            "1         False\n",
            "2         False\n",
            "3          True\n",
            "4         False\n",
            "          ...  \n",
            "169995    False\n",
            "169996    False\n",
            "169997    False\n",
            "169998     True\n",
            "169999    False\n",
            "Name: Rain, Length: 170000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = ['Band Name', 'Band Genre', 'Band Country of Origin', 'Concert Goer Country of Origin','Concert ID', 'Concert Goer ID']\n",
        "for col in x :\n",
        "  print(len(train_data[col].unique()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoDfx3TXgiwQ",
        "outputId": "fefe0317-3465-4fe2-92ee-7a011846df53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55\n",
            "9\n",
            "5\n",
            "153\n",
            "1001\n",
            "2001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpDiv1Acoln8",
        "outputId": "a18897ee-0795-4df5-bd59-d0980b903aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30000 entries, 0 to 29999\n",
            "Data columns (total 18 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   Id                              30000 non-null  object \n",
            " 1   Band Name                       29864 non-null  object \n",
            " 2   Band Genre                      29862 non-null  object \n",
            " 3   Band Country of Origin          29843 non-null  object \n",
            " 4   Band Debut                      29843 non-null  float64\n",
            " 5   Concert ID                      29842 non-null  float64\n",
            " 6   Concert Attendance              29848 non-null  float64\n",
            " 7   Inside Venue                    29834 non-null  object \n",
            " 8   Rain                            29857 non-null  object \n",
            " 9   Seated                          29858 non-null  object \n",
            " 10  Personnality Trait 1            29865 non-null  float64\n",
            " 11  Personnality Trait 2            29847 non-null  float64\n",
            " 12  Personnality Trait 3            29851 non-null  float64\n",
            " 13  Personnality Trait 4            29862 non-null  float64\n",
            " 14  Concert Goer Age                29874 non-null  float64\n",
            " 15  Concert Goer ID                 29855 non-null  object \n",
            " 16  Height (cm)                     29860 non-null  float64\n",
            " 17  Concert Goer Country of Origin  29839 non-null  object \n",
            "dtypes: float64(9), object(9)\n",
            "memory usage: 4.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_unique_goer_id = len(train_data['Concert Goer ID'].unique())\n",
        "number_of_unique_id = len(train_data['Id'].unique())\n",
        "number_of_unique_concert_id = len(train_data['Concert ID'].unique())\n",
        "\n",
        "\n",
        "\n",
        "print(number_of_unique_goer_id)\n",
        "print(number_of_unique_id)\n",
        "print(number_of_unique_concert_id)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7xHmS34YTdy",
        "outputId": "de4e463a-f53d-464b-9314-70a7d88763be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2001\n",
            "170000\n",
            "1001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Concert Enjoyment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqzllCaXdwp9",
        "outputId": "ea4caa81-00b9-491a-8dba-ba162357fc26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Enjoyed               68026\n",
              "Did Not Enjoy         67945\n",
              "Best Concert Ever     17027\n",
              "Worst Concert Ever    17002\n",
              "Name: Concert Enjoyment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = clean_data(train_data, True)\n"
      ],
      "metadata": {
        "id": "Fjk-jo2NXKNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Concert Enjoyment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYYuJuundZvx",
        "outputId": "125d4925-dd69-4c45-cdaa-8fe529ceb611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Enjoyed               62514\n",
              "Did Not Enjoy         62327\n",
              "Worst Concert Ever    15596\n",
              "Best Concert Ever     15586\n",
              "Name: Concert Enjoyment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Data Preprocessing\n"
      ],
      "metadata": {
        "id": "1Y4Avw0EXpKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "def preprocess_target_data(y_data) :\n",
        "  order = ['Worst Concert Ever','Did Not Enjoy','Enjoyed','Best Concert Ever']\n",
        "  encoder = OrdinalEncoder(categories=[order])\n",
        "  y_data = encoder.fit_transform(y_data.to_numpy().reshape(-1,1))\n",
        "  return y_data.reshape((len(y_data))), encoder \n",
        "\n",
        "def decode_predictions(y_predicted, encoder) :\n",
        "  y_predicted = encoder.inverse_transform(y_predicted)\n",
        "  return y_predicted\n",
        "\n",
        "def get_features_preprocessor() :\n",
        "  numeric_features = [\"Band Debut\", \"Concert Attendance\", \"Personnality Trait 1\",\"Personnality Trait 2\",\"Personnality Trait 3\", \"Personnality Trait 4\",\"Concert Goer Age\",\"Height (cm)\"]\n",
        "  numeric_transformer = Pipeline(\n",
        "      steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=0.95))]\n",
        "  )\n",
        "\n",
        "  #features with a low number of class will be one hot encoded\n",
        "  ohe_features = ['Band Name', 'Band Genre', 'Band Country of Origin', 'Concert Goer Country of Origin','Concert ID', 'Concert Goer ID']\n",
        "  ohe_transformer = Pipeline(\n",
        "      steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"OneHotEncoder\", OneHotEncoder())]# great _score with ('SVD', TruncatedSVD(n_components=400))] #('SVD', TruncatedSVD(n_components=0.95))]\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  preprocessor = ColumnTransformer(transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"ohe\", ohe_transformer, ohe_features),\n",
        "    ])\n",
        "  \n",
        "  return preprocessor\n",
        "\n",
        "def find_svd_components(preprocessed_X) :\n",
        "  explained_variance = 0\n",
        "  n_components = 1000\n",
        "  while explained_variance < 0.90 : \n",
        "    svd = TruncatedSVD(n_components = n_components)\n",
        "    svd.fit(preprocessed_X)\n",
        "    explained_variance = svd.explained_variance_ratio_.sum()\n",
        "    print('ncomponent', n_components, 'explained ', explained_variance)\n",
        "    n_components = n_components + 50\n",
        "    break\n",
        "  \n",
        "  print('svd components :', n_components - 10)\n",
        "  return svd\n",
        "\n",
        "\n",
        "def preprocess_features(X, X_to_predict) :\n",
        "  features_preprocessor = get_features_preprocessor()\n",
        "  X = features_preprocessor.fit_transform(X)\n",
        "  X_to_predict = features_preprocessor.transform(X_to_predict)\n",
        "\n",
        "  svd = find_svd_components(X)\n",
        "  X = svd.transform(X)\n",
        "  X_to_predict = svd.transform(X_to_predict)\n",
        "\n",
        "\n",
        "  return X, X_to_predict\n",
        "\n"
      ],
      "metadata": {
        "id": "ocQFM7R0Nin2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_data(data, data_to_predict) : \n",
        "  data, _ = clean_data(data, False)\n",
        "  data_to_predict, Ids = clean_data(data_to_predict, True)\n",
        "  X, y = get_X_y(data)\n",
        "\n",
        "  X, data_to_predict = preprocess_features(X, data_to_predict)\n",
        "\n",
        "  y, y_encoder = preprocess_target_data(y)\n",
        "\n",
        "\n",
        "  return (X, y), (data_to_predict, Ids), y_encoder\n",
        "\n"
      ],
      "metadata": {
        "id": "2pxX5x3NTht_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preprocessed_data() :\n",
        "  data, data_to_predict = get_data_frames()\n",
        "  return preprocess_data(data, data_to_predict)\n",
        "\n",
        "data, data_to_predict, y_encoder = get_preprocessed_data()\n",
        "X, y=  data \n",
        "\n",
        "X_to_predict, Ids = data_to_predict\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(X_to_predict.shape)"
      ],
      "metadata": {
        "id": "1XS3E-xsW2V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b379583-3b63-46f6-d188-c0f69aeed417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ncomponent 1000 explained  0.9174150281677615\n",
            "svd components : 1040\n",
            "(156023, 1000)\n",
            "(156023,)\n",
            "(30000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Model Selection"
      ],
      "metadata": {
        "id": "_BxP4TSkaQvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Shuffle is True\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "vJubY5VdZMQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def grid_search(configurations, X_train, y_train, X_test, y_test, is_base_models) :\n",
        "  best_trained_models = []\n",
        "  for clf, h_parameter in configurations : \n",
        "    print(100*'-')\n",
        "    print(\"Grid search for model :  \",clf, '\\n')\n",
        "    \n",
        "    if is_base_models :\n",
        "       clf = clf(**h_parameter) \n",
        "       clf.fit(X_train, y_train)\n",
        "       best_model_predictions = clf.predict(X_test)\n",
        "       best_trained_models.append(clf)\n",
        "\n",
        "     \n",
        "    else :\n",
        "      grid = GridSearchCV(estimator = clf(),param_grid = h_parameter, cv=3, scoring='f1_micro', verbose = 10, refit = True)# n_jobs = -1)\n",
        "      grid.fit(X_train, y_train)\n",
        "      print('Val score : ', grid.best_score_)\n",
        "      best_model_predictions = grid.predict(X_test)\n",
        "      best_trained_models.append(grid)\n",
        "      print('Best params : ', grid.get_params())\n",
        "\n",
        "    test_score = f1_score(y_test, best_model_predictions, average='micro')\n",
        "    \n",
        "    print(\"Retrained model with all training set Test score : \", test_score)\n",
        "     \n",
        "  return best_trained_models"
      ],
      "metadata": {
        "id": "vBgzeBnSmc7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Study model with base params"
      ],
      "metadata": {
        "id": "xcSPAOYBmevV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, S\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "base_params = {}\n",
        "classifiers_config = [\n",
        "    (RandomForestClassifier, base_params),\n",
        "    (AdaBoostClassifier, base_params),\n",
        "    (GradientBoostingClassifier, base_params),\n",
        "    (MLPClassifier, base_params)\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, True )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "82wIv4iEm3G7",
        "outputId": "52e481e4-c3f9-4b6f-e7f7-b1c8f4f9254a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.ensemble._forest.RandomForestClassifier'> \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fd6edd89366b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m ]\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mbest_trained_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-7c057d7e7c92>\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(configurations, X_train, y_train, X_test, y_test, is_base_models)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_base_models\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m        \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m        \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m        \u001b[0mbest_model_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m        \u001b[0mbest_trained_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 )\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 MLP params tuning\n"
      ],
      "metadata": {
        "id": "ayDuRxYnpQQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp_params = {'hidden_layer_sizes': [ (1000), (500), (50,50,50), (30,30,30,30,30) , (100), (200), (300), (100,100), (200,200), (300,300)], 'early_stopping' : [True], 'alpha' : [0.0001],'solver': ['adam'], 'max_iter': [1000], }\n",
        "\n",
        "classifiers_config = [\n",
        "    (MLPClassifier, mlp_params)\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iuaj0uiJ3i_",
        "outputId": "4d81cc0e-318b-4722-d6d1-90e236049599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV 1/3; 1/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam\n",
            "[CV 1/3; 1/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam;, score=0.648 total time= 4.5min\n",
            "[CV 2/3; 1/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam\n",
            "[CV 2/3; 1/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam;, score=0.644 total time= 4.3min\n",
            "[CV 3/3; 1/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam\n",
            "[CV 3/3; 1/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam;, score=0.645 total time= 4.3min\n",
            "[CV 1/3; 2/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam\n",
            "[CV 1/3; 2/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam;, score=0.645 total time= 2.5min\n",
            "[CV 2/3; 2/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam\n",
            "[CV 2/3; 2/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam;, score=0.642 total time= 2.4min\n",
            "[CV 3/3; 2/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam\n",
            "[CV 3/3; 2/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam;, score=0.640 total time= 1.9min\n",
            "[CV 1/3; 3/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam\n",
            "[CV 1/3; 3/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam;, score=0.644 total time=  42.1s\n",
            "[CV 2/3; 3/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam\n",
            "[CV 2/3; 3/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam;, score=0.643 total time=  40.2s\n",
            "[CV 3/3; 3/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam\n",
            "[CV 3/3; 3/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam;, score=0.648 total time=  40.8s\n",
            "[CV 1/3; 4/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam\n",
            "[CV 1/3; 4/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam;, score=0.653 total time=  33.7s\n",
            "[CV 2/3; 4/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam\n",
            "[CV 2/3; 4/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam;, score=0.646 total time=  30.2s\n",
            "[CV 3/3; 4/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam\n",
            "[CV 3/3; 4/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam;, score=0.647 total time=  39.5s\n",
            "[CV 1/3; 5/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam\n",
            "[CV 1/3; 5/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam;, score=0.645 total time=  59.5s\n",
            "[CV 2/3; 5/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam\n",
            "[CV 2/3; 5/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam;, score=0.639 total time=  54.2s\n",
            "[CV 3/3; 5/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam\n",
            "[CV 3/3; 5/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam;, score=0.637 total time=  39.3s\n",
            "[CV 1/3; 6/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam\n",
            "[CV 1/3; 6/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam;, score=0.647 total time= 1.0min\n",
            "[CV 2/3; 6/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam\n",
            "[CV 2/3; 6/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam;, score=0.640 total time= 1.1min\n",
            "[CV 3/3; 6/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam\n",
            "[CV 3/3; 6/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam;, score=0.642 total time= 1.1min\n",
            "[CV 1/3; 7/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam\n",
            "[CV 1/3; 7/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam;, score=0.648 total time= 1.7min\n",
            "[CV 2/3; 7/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam\n",
            "[CV 2/3; 7/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam;, score=0.642 total time= 1.8min\n",
            "[CV 3/3; 7/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam\n",
            "[CV 3/3; 7/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam;, score=0.646 total time= 1.5min\n",
            "[CV 1/3; 8/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam\n",
            "[CV 1/3; 8/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam;, score=0.648 total time=  44.8s\n",
            "[CV 2/3; 8/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam\n",
            "[CV 2/3; 8/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam;, score=0.640 total time=  51.2s\n",
            "[CV 3/3; 8/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam\n",
            "[CV 3/3; 8/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam;, score=0.650 total time=  47.4s\n",
            "[CV 1/3; 9/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam\n",
            "[CV 1/3; 9/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam;, score=0.648 total time= 1.2min\n",
            "[CV 2/3; 9/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam\n",
            "[CV 2/3; 9/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam;, score=0.642 total time= 1.2min\n",
            "[CV 3/3; 9/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam\n",
            "[CV 3/3; 9/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam;, score=0.650 total time= 1.3min\n",
            "[CV 1/3; 10/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam\n",
            "[CV 1/3; 10/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam;, score=0.647 total time= 2.0min\n",
            "[CV 2/3; 10/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam\n",
            "[CV 2/3; 10/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam;, score=0.644 total time= 1.7min\n",
            "[CV 3/3; 10/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam\n",
            "[CV 3/3; 10/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam;, score=0.648 total time= 1.7min\n",
            "Val score :  0.6485587798432562\n",
            "Best params :  {'cv': 3, 'error_score': nan, 'estimator__activation': 'relu', 'estimator__alpha': 0.0001, 'estimator__batch_size': 'auto', 'estimator__beta_1': 0.9, 'estimator__beta_2': 0.999, 'estimator__early_stopping': False, 'estimator__epsilon': 1e-08, 'estimator__hidden_layer_sizes': (100,), 'estimator__learning_rate': 'constant', 'estimator__learning_rate_init': 0.001, 'estimator__max_fun': 15000, 'estimator__max_iter': 200, 'estimator__momentum': 0.9, 'estimator__n_iter_no_change': 10, 'estimator__nesterovs_momentum': True, 'estimator__power_t': 0.5, 'estimator__random_state': None, 'estimator__shuffle': True, 'estimator__solver': 'adam', 'estimator__tol': 0.0001, 'estimator__validation_fraction': 0.1, 'estimator__verbose': False, 'estimator__warm_start': False, 'estimator': MLPClassifier(), 'n_jobs': None, 'param_grid': {'hidden_layer_sizes': [1000, 500, (50, 50, 50), (30, 30, 30, 30, 30), 100, 200, 300, (100, 100), (200, 200), (300, 300)], 'early_stopping': [True], 'alpha': [0.0001], 'solver': ['adam'], 'max_iter': [1000]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': 'f1_micro', 'verbose': 10}\n",
            "Retrained model with all training set Test score :  0.6547952229367402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GradBoosting"
      ],
      "metadata": {
        "id": "D_yQdcmWIigA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "1KavPocrImWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbc_params = {'n_estimators':[100, 300, 500, 1000], 'max_depth':[3,5,6]}\n",
        "\n",
        "classifiers_config = [\n",
        "    (GradientBoostingClassifier, gbc_params)\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "id": "z4XkKgnDKNAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0959d74a-79b6-43d7-ba8b-6b70ecf9962d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.ensemble._gb.GradientBoostingClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "[CV 1/3; 1/12] START max_depth=3, n_estimators=100..............................\n",
            "[CV 1/3; 1/12] END max_depth=3, n_estimators=100;, score=0.626 total time=416.6min\n",
            "[CV 2/3; 1/12] START max_depth=3, n_estimators=100..............................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc_params = {'n_estimators':[50,75,100,150, 200, 300]}\n",
        "\n",
        "classifiers_config = [\n",
        "    (RandomForestClassifier, rfc_params),\n",
        "    (SVC,  {})\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "id": "nD8rdlWLJqht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95ea0f6-9db7-494a-ec96-49db4d67a79d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.ensemble._forest.RandomForestClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "[CV 1/3; 1/6] START n_estimators=50.............................................\n",
            "[CV 1/3; 1/6] END ..............n_estimators=50;, score=0.626 total time= 3.8min\n",
            "[CV 2/3; 1/6] START n_estimators=50.............................................\n",
            "[CV 2/3; 1/6] END ..............n_estimators=50;, score=0.622 total time= 3.9min\n",
            "[CV 3/3; 1/6] START n_estimators=50.............................................\n",
            "[CV 3/3; 1/6] END ..............n_estimators=50;, score=0.622 total time= 3.8min\n",
            "[CV 1/3; 2/6] START n_estimators=75.............................................\n",
            "[CV 1/3; 2/6] END ..............n_estimators=75;, score=0.628 total time= 5.9min\n",
            "[CV 2/3; 2/6] START n_estimators=75.............................................\n",
            "[CV 2/3; 2/6] END ..............n_estimators=75;, score=0.626 total time= 5.8min\n",
            "[CV 3/3; 2/6] START n_estimators=75.............................................\n",
            "[CV 3/3; 2/6] END ..............n_estimators=75;, score=0.624 total time= 5.8min\n",
            "[CV 1/3; 3/6] START n_estimators=100............................................\n",
            "[CV 1/3; 3/6] END .............n_estimators=100;, score=0.631 total time= 7.5min\n",
            "[CV 2/3; 3/6] START n_estimators=100............................................\n",
            "[CV 2/3; 3/6] END .............n_estimators=100;, score=0.627 total time= 7.6min\n",
            "[CV 3/3; 3/6] START n_estimators=100............................................\n",
            "[CV 3/3; 3/6] END .............n_estimators=100;, score=0.627 total time= 7.5min\n",
            "[CV 1/3; 4/6] START n_estimators=150............................................\n",
            "[CV 1/3; 4/6] END .............n_estimators=150;, score=0.633 total time=11.7min\n",
            "[CV 2/3; 4/6] START n_estimators=150............................................\n",
            "[CV 2/3; 4/6] END .............n_estimators=150;, score=0.629 total time=11.7min\n",
            "[CV 3/3; 4/6] START n_estimators=150............................................\n",
            "[CV 3/3; 4/6] END .............n_estimators=150;, score=0.630 total time=11.9min\n",
            "[CV 1/3; 5/6] START n_estimators=200............................................\n",
            "[CV 1/3; 5/6] END .............n_estimators=200;, score=0.635 total time=15.5min\n",
            "[CV 2/3; 5/6] START n_estimators=200............................................\n",
            "[CV 2/3; 5/6] END .............n_estimators=200;, score=0.628 total time=15.5min\n",
            "[CV 3/3; 5/6] START n_estimators=200............................................\n",
            "[CV 3/3; 5/6] END .............n_estimators=200;, score=0.631 total time=15.3min\n",
            "[CV 1/3; 6/6] START n_estimators=300............................................\n",
            "[CV 1/3; 6/6] END .............n_estimators=300;, score=0.635 total time=23.0min\n",
            "[CV 2/3; 6/6] START n_estimators=300............................................\n",
            "[CV 2/3; 6/6] END .............n_estimators=300;, score=0.630 total time=23.5min\n",
            "[CV 3/3; 6/6] START n_estimators=300............................................\n",
            "[CV 3/3; 6/6] END .............n_estimators=300;, score=0.631 total time=22.6min\n",
            "Val score :  0.6317938454422293\n",
            "Best params :  {'cv': 3, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'n_jobs': None, 'param_grid': {'n_estimators': [50, 75, 100, 150, 200, 300]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': 'f1_micro', 'verbose': 10}\n",
            "Retrained model with all training set Test score :  0.6353109577627278\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.svm._classes.SVC'> \n",
            "\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3; 1/1] START ............................................................\n",
            "[CV 1/3; 1/1] END ............................., score=0.637 total time=139.8min\n",
            "[CV 2/3; 1/1] START ............................................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc_params = {'n_estimators':[500,750,1000,1500]}\n",
        "\n",
        "classifiers_config = [\n",
        "    (RandomForestClassifier, rfc_params),\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_eivhGrC4Q8",
        "outputId": "cc0cc184-35fb-4c91-ed0f-0cf76abc0f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.ensemble._forest.RandomForestClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "[CV 1/3; 1/4] START n_estimators=500............................................\n",
            "[CV 1/3; 1/4] END .............n_estimators=500;, score=0.637 total time=33.0min\n",
            "[CV 2/3; 1/4] START n_estimators=500............................................\n",
            "[CV 2/3; 1/4] END .............n_estimators=500;, score=0.630 total time=32.8min\n",
            "[CV 3/3; 1/4] START n_estimators=500............................................\n",
            "[CV 3/3; 1/4] END .............n_estimators=500;, score=0.632 total time=32.9min\n",
            "[CV 1/3; 2/4] START n_estimators=750............................................\n",
            "[CV 1/3; 2/4] END .............n_estimators=750;, score=0.636 total time=49.0min\n",
            "[CV 2/3; 2/4] START n_estimators=750............................................\n",
            "[CV 2/3; 2/4] END .............n_estimators=750;, score=0.631 total time=49.2min\n",
            "[CV 3/3; 2/4] START n_estimators=750............................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc_params = {'n_estimators':[100,300, 500,600], 'class_weight': ['balanced']}\n",
        "\n",
        "classifiers_config = [\n",
        "    (RandomForestClassifier, rfc_params),\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox17gK4ZqkAc",
        "outputId": "7e2a436f-2f27-4eb6-d3f4-0011fddebe70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.ensemble._forest.RandomForestClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "[CV 1/3; 1/4] START class_weight=balanced, n_estimators=100.....................\n",
            "[CV 1/3; 1/4] END class_weight=balanced, n_estimators=100;, score=0.631 total time= 5.7min\n",
            "[CV 2/3; 1/4] START class_weight=balanced, n_estimators=100.....................\n",
            "[CV 2/3; 1/4] END class_weight=balanced, n_estimators=100;, score=0.625 total time= 5.7min\n",
            "[CV 3/3; 1/4] START class_weight=balanced, n_estimators=100.....................\n",
            "[CV 3/3; 1/4] END class_weight=balanced, n_estimators=100;, score=0.627 total time= 5.7min\n",
            "[CV 1/3; 2/4] START class_weight=balanced, n_estimators=300.....................\n",
            "[CV 1/3; 2/4] END class_weight=balanced, n_estimators=300;, score=0.632 total time=17.2min\n",
            "[CV 2/3; 2/4] START class_weight=balanced, n_estimators=300.....................\n",
            "[CV 2/3; 2/4] END class_weight=balanced, n_estimators=300;, score=0.629 total time=17.2min\n",
            "[CV 3/3; 2/4] START class_weight=balanced, n_estimators=300.....................\n",
            "[CV 3/3; 2/4] END class_weight=balanced, n_estimators=300;, score=0.629 total time=17.0min\n",
            "[CV 1/3; 3/4] START class_weight=balanced, n_estimators=500.....................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_params = {'n_neighbors': [25,50,150,200,250, 500]}#5, 10, 15, 20, 25, 50, 100,200]}\n",
        "classifiers_config = [\n",
        "    (KNeighborsClassifier, knn_params)\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRmWIeeVtFJK",
        "outputId": "4686ccbf-1321-44b2-e3e6-6fa5582598d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.neighbors._classification.KNeighborsClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "[CV 1/3; 1/6] START n_neighbors=25..............................................\n",
            "[CV 1/3; 1/6] END ...............n_neighbors=25;, score=0.604 total time= 2.1min\n",
            "[CV 2/3; 1/6] START n_neighbors=25..............................................\n",
            "[CV 2/3; 1/6] END ...............n_neighbors=25;, score=0.602 total time= 2.0min\n",
            "[CV 3/3; 1/6] START n_neighbors=25..............................................\n",
            "[CV 3/3; 1/6] END ...............n_neighbors=25;, score=0.604 total time= 2.1min\n",
            "[CV 1/3; 2/6] START n_neighbors=50..............................................\n",
            "[CV 1/3; 2/6] END ...............n_neighbors=50;, score=0.605 total time= 2.1min\n",
            "[CV 2/3; 2/6] START n_neighbors=50..............................................\n",
            "[CV 2/3; 2/6] END ...............n_neighbors=50;, score=0.603 total time= 2.1min\n",
            "[CV 3/3; 2/6] START n_neighbors=50..............................................\n",
            "[CV 3/3; 2/6] END ...............n_neighbors=50;, score=0.605 total time= 2.0min\n",
            "[CV 1/3; 3/6] START n_neighbors=150.............................................\n",
            "[CV 1/3; 3/6] END ..............n_neighbors=150;, score=0.600 total time= 2.1min\n",
            "[CV 2/3; 3/6] START n_neighbors=150.............................................\n",
            "[CV 2/3; 3/6] END ..............n_neighbors=150;, score=0.598 total time= 2.1min\n",
            "[CV 3/3; 3/6] START n_neighbors=150.............................................\n",
            "[CV 3/3; 3/6] END ..............n_neighbors=150;, score=0.597 total time= 2.0min\n",
            "[CV 1/3; 4/6] START n_neighbors=200.............................................\n",
            "[CV 1/3; 4/6] END ..............n_neighbors=200;, score=0.597 total time= 2.1min\n",
            "[CV 2/3; 4/6] START n_neighbors=200.............................................\n",
            "[CV 2/3; 4/6] END ..............n_neighbors=200;, score=0.595 total time= 2.0min\n",
            "[CV 3/3; 4/6] START n_neighbors=200.............................................\n",
            "[CV 3/3; 4/6] END ..............n_neighbors=200;, score=0.595 total time= 2.0min\n",
            "[CV 1/3; 5/6] START n_neighbors=250.............................................\n",
            "[CV 1/3; 5/6] END ..............n_neighbors=250;, score=0.594 total time= 2.1min\n",
            "[CV 2/3; 5/6] START n_neighbors=250.............................................\n",
            "[CV 2/3; 5/6] END ..............n_neighbors=250;, score=0.593 total time= 2.0min\n",
            "[CV 3/3; 5/6] START n_neighbors=250.............................................\n",
            "[CV 3/3; 5/6] END ..............n_neighbors=250;, score=0.593 total time= 2.1min\n",
            "[CV 1/3; 6/6] START n_neighbors=500.............................................\n",
            "[CV 1/3; 6/6] END ..............n_neighbors=500;, score=0.586 total time= 2.1min\n",
            "[CV 2/3; 6/6] START n_neighbors=500.............................................\n",
            "[CV 2/3; 6/6] END ..............n_neighbors=500;, score=0.586 total time= 2.1min\n",
            "[CV 3/3; 6/6] START n_neighbors=500.............................................\n",
            "[CV 3/3; 6/6] END ..............n_neighbors=500;, score=0.584 total time= 2.1min\n",
            "Val score :  0.604499335575707\n",
            "Best params :  {'cv': 3, 'error_score': nan, 'estimator__algorithm': 'auto', 'estimator__leaf_size': 30, 'estimator__metric': 'minkowski', 'estimator__metric_params': None, 'estimator__n_jobs': None, 'estimator__n_neighbors': 5, 'estimator__p': 2, 'estimator__weights': 'uniform', 'estimator': KNeighborsClassifier(), 'n_jobs': None, 'param_grid': {'n_neighbors': [25, 50, 150, 200, 250, 500]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': 'f1_micro', 'verbose': 10}\n",
            "Retrained model with all training set Test score :  0.6121092998910419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report Generation"
      ],
      "metadata": {
        "id": "B2R3ByrXaY_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "def generate_predictions_report(best_trained_models, data_to_predict, y_encoder) :\n",
        "  X_to_predict, Ids = data_to_predict\n",
        "  for idx,model in enumerate(best_trained_models) :\n",
        "    \n",
        "    predictions = model.predict(X_to_predict)\n",
        "    predictions = decode_predictions(predictions.reshape(-1,1), y_encoder).reshape(len(predictions))\n",
        "    report = pd.DataFrame({'Id': Ids, 'Predicted' : predictions })\n",
        "\n",
        "    report.to_csv(f'{idx}_report.csv', index = False)\n",
        "    files.download(f'{idx}_report.csv')\n",
        "\n",
        "generate_predictions_report(best_trained_models, data_to_predict, y_encoder)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "rCQi6EOfhDDk",
        "outputId": "dde7d31d-4bb4-4f94-b909-bb7beeed398a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6fcc45c3-1c4f-4aab-bd7f-edae17c673b9\", \"0_report.csv\", 1081612)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}