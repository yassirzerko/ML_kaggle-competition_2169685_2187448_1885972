{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Important** : As mentionned in the readme : To run the notebook, make sure you have files named train.csv and test.csv in the runtime environment base folder such that google colab code can access training and test data with urls: train.csv and test.csv."
      ],
      "metadata": {
        "id": "CfuX-Io71vdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "\n"
      ],
      "metadata": {
        "id": "5kJ5wJw9OXLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10b76ae-1cbc-4338-99f0-0e51e60b2964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "IlawQ1QhPd_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial data exploration and removing empty rows"
      ],
      "metadata": {
        "id": "G1YGp_JfX1bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_frames() :\n",
        "  data = pd.read_csv('train.csv')\n",
        "  data_to_predict = pd.read_csv('test.csv')\n",
        "  return (data, data_to_predict)\n",
        "\n",
        "def clean_data(data, is_data_to_predict) :\n",
        "  columns_to_drop = ['Id']#, 'Concert ID', 'Concert Goer ID']\n",
        "  Ids = data['Id']\n",
        "  data = data.drop(columns=columns_to_drop)\n",
        "  if not is_data_to_predict : \n",
        "      data = data.dropna()\n",
        "  return data, Ids\n",
        "\n",
        "def get_X_y(data) :\n",
        "  target_variable = 'Concert Enjoyment'\n",
        "  X = data.drop(columns = [target_variable])\n",
        "  y = data[target_variable]\n",
        "\n",
        "  return X,y\n"
      ],
      "metadata": {
        "id": "Yu1aqtxEMQS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = get_data_frames()\n",
        "na_rows = train_data.isna().any(axis=1)\n",
        "number_of_invalid_row = np.sum(na_rows)\n",
        "number_of_row = len(train_data)\n",
        "\n",
        "print('% of invalid lines', (number_of_invalid_row/ number_of_row) * 100, ' %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zplYNzgmTMSq",
        "outputId": "c0b4b8fc-c0ba-46f5-eaf6-56173837065d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of invalid lines 8.221764705882354  %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()\n",
        "print(train_data['Rain'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXSk1JvEWK4g",
        "outputId": "8bee0e46-104f-4d76-b0c8-774f52497f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 170000 entries, 0 to 169999\n",
            "Data columns (total 19 columns):\n",
            " #   Column                          Non-Null Count   Dtype  \n",
            "---  ------                          --------------   -----  \n",
            " 0   Id                              170000 non-null  object \n",
            " 1   Band Name                       169141 non-null  object \n",
            " 2   Band Genre                      169116 non-null  object \n",
            " 3   Band Country of Origin          169210 non-null  object \n",
            " 4   Band Debut                      169143 non-null  float64\n",
            " 5   Concert ID                      169130 non-null  float64\n",
            " 6   Concert Attendance              169105 non-null  float64\n",
            " 7   Inside Venue                    169162 non-null  object \n",
            " 8   Rain                            169139 non-null  object \n",
            " 9   Seated                          169168 non-null  object \n",
            " 10  Personnality Trait 1            169148 non-null  float64\n",
            " 11  Personnality Trait 2            169151 non-null  float64\n",
            " 12  Personnality Trait 3            169107 non-null  float64\n",
            " 13  Personnality Trait 4            169135 non-null  float64\n",
            " 14  Concert Goer Age                169147 non-null  float64\n",
            " 15  Concert Goer ID                 169185 non-null  object \n",
            " 16  Height (cm)                     169153 non-null  float64\n",
            " 17  Concert Goer Country of Origin  169141 non-null  object \n",
            " 18  Concert Enjoyment               170000 non-null  object \n",
            "dtypes: float64(9), object(10)\n",
            "memory usage: 24.6+ MB\n",
            "0         False\n",
            "1         False\n",
            "2         False\n",
            "3          True\n",
            "4         False\n",
            "          ...  \n",
            "169995    False\n",
            "169996    False\n",
            "169997    False\n",
            "169998     True\n",
            "169999    False\n",
            "Name: Rain, Length: 170000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = ['Band Name', 'Band Genre', 'Band Country of Origin', 'Concert Goer Country of Origin','Concert ID', 'Concert Goer ID']\n",
        "for col in x :\n",
        "  print(len(train_data[col].unique()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoDfx3TXgiwQ",
        "outputId": "fefe0317-3465-4fe2-92ee-7a011846df53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55\n",
            "9\n",
            "5\n",
            "153\n",
            "1001\n",
            "2001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpDiv1Acoln8",
        "outputId": "a18897ee-0795-4df5-bd59-d0980b903aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30000 entries, 0 to 29999\n",
            "Data columns (total 18 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   Id                              30000 non-null  object \n",
            " 1   Band Name                       29864 non-null  object \n",
            " 2   Band Genre                      29862 non-null  object \n",
            " 3   Band Country of Origin          29843 non-null  object \n",
            " 4   Band Debut                      29843 non-null  float64\n",
            " 5   Concert ID                      29842 non-null  float64\n",
            " 6   Concert Attendance              29848 non-null  float64\n",
            " 7   Inside Venue                    29834 non-null  object \n",
            " 8   Rain                            29857 non-null  object \n",
            " 9   Seated                          29858 non-null  object \n",
            " 10  Personnality Trait 1            29865 non-null  float64\n",
            " 11  Personnality Trait 2            29847 non-null  float64\n",
            " 12  Personnality Trait 3            29851 non-null  float64\n",
            " 13  Personnality Trait 4            29862 non-null  float64\n",
            " 14  Concert Goer Age                29874 non-null  float64\n",
            " 15  Concert Goer ID                 29855 non-null  object \n",
            " 16  Height (cm)                     29860 non-null  float64\n",
            " 17  Concert Goer Country of Origin  29839 non-null  object \n",
            "dtypes: float64(9), object(9)\n",
            "memory usage: 4.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_unique_goer_id = len(train_data['Concert Goer ID'].unique())\n",
        "number_of_unique_id = len(train_data['Id'].unique())\n",
        "number_of_unique_concert_id = len(train_data['Concert ID'].unique())\n",
        "\n",
        "\n",
        "\n",
        "print(number_of_unique_goer_id)\n",
        "print(number_of_unique_id)\n",
        "print(number_of_unique_concert_id)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7xHmS34YTdy",
        "outputId": "de4e463a-f53d-464b-9314-70a7d88763be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2001\n",
            "170000\n",
            "1001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Concert Enjoyment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqzllCaXdwp9",
        "outputId": "ea4caa81-00b9-491a-8dba-ba162357fc26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Enjoyed               68026\n",
              "Did Not Enjoy         67945\n",
              "Best Concert Ever     17027\n",
              "Worst Concert Ever    17002\n",
              "Name: Concert Enjoyment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = clean_data(train_data, True)\n"
      ],
      "metadata": {
        "id": "Fjk-jo2NXKNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Concert Enjoyment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYYuJuundZvx",
        "outputId": "125d4925-dd69-4c45-cdaa-8fe529ceb611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Enjoyed               62514\n",
              "Did Not Enjoy         62327\n",
              "Worst Concert Ever    15596\n",
              "Best Concert Ever     15586\n",
              "Name: Concert Enjoyment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Data Preprocessing\n"
      ],
      "metadata": {
        "id": "1Y4Avw0EXpKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "def preprocess_target_data(y_data) :\n",
        "  order = ['Worst Concert Ever','Did Not Enjoy','Enjoyed','Best Concert Ever']\n",
        "  encoder = OrdinalEncoder(categories=[order])\n",
        "  y_data = encoder.fit_transform(y_data.to_numpy().reshape(-1,1))\n",
        "  return y_data.reshape((len(y_data))), encoder \n",
        "\n",
        "def decode_predictions(y_predicted, encoder) :\n",
        "  y_predicted = encoder.inverse_transform(y_predicted)\n",
        "  return y_predicted\n",
        "\n",
        "def get_features_preprocessor() :\n",
        "  numeric_features = [\"Band Debut\", \"Concert Attendance\", \"Personnality Trait 1\",\"Personnality Trait 2\",\"Personnality Trait 3\", \"Personnality Trait 4\",\"Concert Goer Age\",\"Height (cm)\"]\n",
        "  numeric_transformer = Pipeline(\n",
        "      steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=0.95))]\n",
        "  )\n",
        "\n",
        "  #features with a low number of class will be one hot encoded\n",
        "  ohe_features = ['Band Name', 'Band Genre', 'Band Country of Origin', 'Concert Goer Country of Origin','Concert ID', 'Concert Goer ID']\n",
        "  ohe_transformer = Pipeline(\n",
        "      steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"OneHotEncoder\", OneHotEncoder())]# great _score with ('SVD', TruncatedSVD(n_components=400))] #('SVD', TruncatedSVD(n_components=0.95))]\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  preprocessor = ColumnTransformer(transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"ohe\", ohe_transformer, ohe_features),\n",
        "    ])\n",
        "  \n",
        "  return preprocessor\n",
        "\n",
        "def find_svd_components(preprocessed_X) :\n",
        "  explained_variance = 0\n",
        "  n_components = 1000\n",
        "  while explained_variance < 0.90 : \n",
        "    svd = TruncatedSVD(n_components = n_components)\n",
        "    svd.fit(preprocessed_X)\n",
        "    explained_variance = svd.explained_variance_ratio_.sum()\n",
        "    print('ncomponent', n_components, 'explained ', explained_variance)\n",
        "    n_components = n_components + 50\n",
        "    break\n",
        "  \n",
        "  print('svd components :', n_components - 10)\n",
        "  return svd\n",
        "\n",
        "\n",
        "def preprocess_features(X, X_to_predict) :\n",
        "  features_preprocessor = get_features_preprocessor()\n",
        "  X = features_preprocessor.fit_transform(X)\n",
        "  X_to_predict = features_preprocessor.transform(X_to_predict)\n",
        "\n",
        "  svd = find_svd_components(X)\n",
        "  X = svd.transform(X)\n",
        "  X_to_predict = svd.transform(X_to_predict)\n",
        "\n",
        "\n",
        "  return X, X_to_predict\n",
        "\n"
      ],
      "metadata": {
        "id": "ocQFM7R0Nin2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_data(data, data_to_predict) : \n",
        "  data, _ = clean_data(data, False)\n",
        "  data_to_predict, Ids = clean_data(data_to_predict, True)\n",
        "  X, y = get_X_y(data)\n",
        "\n",
        "  X, data_to_predict = preprocess_features(X, data_to_predict)\n",
        "\n",
        "  y, y_encoder = preprocess_target_data(y)\n",
        "\n",
        "\n",
        "  return (X, y), (data_to_predict, Ids), y_encoder\n",
        "\n"
      ],
      "metadata": {
        "id": "2pxX5x3NTht_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preprocessed_data() :\n",
        "  data, data_to_predict = get_data_frames()\n",
        "  return preprocess_data(data, data_to_predict)\n",
        "\n",
        "data, data_to_predict, y_encoder = get_preprocessed_data()\n",
        "X, y=  data \n",
        "\n",
        "X_to_predict, Ids = data_to_predict\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(X_to_predict.shape)"
      ],
      "metadata": {
        "id": "1XS3E-xsW2V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b379583-3b63-46f6-d188-c0f69aeed417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ncomponent 1000 explained  0.9174150281677615\n",
            "svd components : 1040\n",
            "(156023, 1000)\n",
            "(156023,)\n",
            "(30000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Model Selection"
      ],
      "metadata": {
        "id": "_BxP4TSkaQvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Shuffle is True\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "vJubY5VdZMQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def grid_search(configurations, X_train, y_train, X_test, y_test, is_base_models) :\n",
        "  best_trained_models = []\n",
        "  for clf, h_parameter in configurations : \n",
        "    print(100*'-')\n",
        "    print(\"Grid search for model :  \",clf, '\\n')\n",
        "    \n",
        "    if is_base_models :\n",
        "       clf = clf(**h_parameter) \n",
        "       clf.fit(X_train, y_train)\n",
        "       best_model_predictions = clf.predict(X_test)\n",
        "       best_trained_models.append(clf)\n",
        "\n",
        "     \n",
        "    else :\n",
        "      grid = GridSearchCV(estimator = clf(),param_grid = h_parameter, cv=3, scoring='f1_micro', verbose = 10, refit = True)# n_jobs = -1)\n",
        "      grid.fit(X_train, y_train)\n",
        "      print('Val score : ', grid.best_score_)\n",
        "      best_model_predictions = grid.predict(X_test)\n",
        "      best_trained_models.append(grid)\n",
        "      print('Best params : ', grid.get_params())\n",
        "\n",
        "    test_score = f1_score(y_test, best_model_predictions, average='micro')\n",
        "    \n",
        "    print(\"Retrained model with all training set Test score : \", test_score)\n",
        "     \n",
        "  return best_trained_models"
      ],
      "metadata": {
        "id": "vBgzeBnSmc7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Study model with base params"
      ],
      "metadata": {
        "id": "xcSPAOYBmevV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, S\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "base_params = {}\n",
        "classifiers_config = [\n",
        "    (RandomForestClassifier, base_params),\n",
        "    (AdaBoostClassifier, base_params),\n",
        "    (GradientBoostingClassifier, base_params),\n",
        "    (MLPClassifier, base_params)\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, True )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "82wIv4iEm3G7",
        "outputId": "52e481e4-c3f9-4b6f-e7f7-b1c8f4f9254a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.ensemble._forest.RandomForestClassifier'> \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fd6edd89366b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m ]\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mbest_trained_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-7c057d7e7c92>\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(configurations, X_train, y_train, X_test, y_test, is_base_models)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_base_models\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m        \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m        \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m        \u001b[0mbest_model_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m        \u001b[0mbest_trained_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 )\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 MLP params tuning\n"
      ],
      "metadata": {
        "id": "ayDuRxYnpQQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp_params = {'hidden_layer_sizes': [ (1000), (500), (50,50,50), (30,30,30,30,30) , (100), (200), (300), (100,100), (200,200), (300,300)], 'early_stopping' : [True], 'alpha' : [0.0001],'solver': ['adam'], 'max_iter': [1000], }\n",
        "\n",
        "classifiers_config = [\n",
        "    (MLPClassifier, mlp_params)\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iuaj0uiJ3i_",
        "outputId": "4d81cc0e-318b-4722-d6d1-90e236049599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV 1/3; 1/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam\n",
            "[CV 1/3; 1/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam;, score=0.648 total time= 4.5min\n",
            "[CV 2/3; 1/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam\n",
            "[CV 2/3; 1/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam;, score=0.644 total time= 4.3min\n",
            "[CV 3/3; 1/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam\n",
            "[CV 3/3; 1/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=1000, max_iter=1000, solver=adam;, score=0.645 total time= 4.3min\n",
            "[CV 1/3; 2/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam\n",
            "[CV 1/3; 2/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam;, score=0.645 total time= 2.5min\n",
            "[CV 2/3; 2/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam\n",
            "[CV 2/3; 2/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam;, score=0.642 total time= 2.4min\n",
            "[CV 3/3; 2/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam\n",
            "[CV 3/3; 2/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=500, max_iter=1000, solver=adam;, score=0.640 total time= 1.9min\n",
            "[CV 1/3; 3/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam\n",
            "[CV 1/3; 3/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam;, score=0.644 total time=  42.1s\n",
            "[CV 2/3; 3/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam\n",
            "[CV 2/3; 3/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam;, score=0.643 total time=  40.2s\n",
            "[CV 3/3; 3/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam\n",
            "[CV 3/3; 3/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(50, 50, 50), max_iter=1000, solver=adam;, score=0.648 total time=  40.8s\n",
            "[CV 1/3; 4/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam\n",
            "[CV 1/3; 4/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam;, score=0.653 total time=  33.7s\n",
            "[CV 2/3; 4/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam\n",
            "[CV 2/3; 4/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam;, score=0.646 total time=  30.2s\n",
            "[CV 3/3; 4/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam\n",
            "[CV 3/3; 4/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(30, 30, 30, 30, 30), max_iter=1000, solver=adam;, score=0.647 total time=  39.5s\n",
            "[CV 1/3; 5/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam\n",
            "[CV 1/3; 5/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam;, score=0.645 total time=  59.5s\n",
            "[CV 2/3; 5/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam\n",
            "[CV 2/3; 5/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam;, score=0.639 total time=  54.2s\n",
            "[CV 3/3; 5/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam\n",
            "[CV 3/3; 5/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=100, max_iter=1000, solver=adam;, score=0.637 total time=  39.3s\n",
            "[CV 1/3; 6/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam\n",
            "[CV 1/3; 6/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam;, score=0.647 total time= 1.0min\n",
            "[CV 2/3; 6/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam\n",
            "[CV 2/3; 6/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam;, score=0.640 total time= 1.1min\n",
            "[CV 3/3; 6/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam\n",
            "[CV 3/3; 6/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=200, max_iter=1000, solver=adam;, score=0.642 total time= 1.1min\n",
            "[CV 1/3; 7/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam\n",
            "[CV 1/3; 7/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam;, score=0.648 total time= 1.7min\n",
            "[CV 2/3; 7/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam\n",
            "[CV 2/3; 7/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam;, score=0.642 total time= 1.8min\n",
            "[CV 3/3; 7/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam\n",
            "[CV 3/3; 7/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=300, max_iter=1000, solver=adam;, score=0.646 total time= 1.5min\n",
            "[CV 1/3; 8/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam\n",
            "[CV 1/3; 8/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam;, score=0.648 total time=  44.8s\n",
            "[CV 2/3; 8/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam\n",
            "[CV 2/3; 8/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam;, score=0.640 total time=  51.2s\n",
            "[CV 3/3; 8/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam\n",
            "[CV 3/3; 8/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=1000, solver=adam;, score=0.650 total time=  47.4s\n",
            "[CV 1/3; 9/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam\n",
            "[CV 1/3; 9/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam;, score=0.648 total time= 1.2min\n",
            "[CV 2/3; 9/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam\n",
            "[CV 2/3; 9/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam;, score=0.642 total time= 1.2min\n",
            "[CV 3/3; 9/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam\n",
            "[CV 3/3; 9/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(200, 200), max_iter=1000, solver=adam;, score=0.650 total time= 1.3min\n",
            "[CV 1/3; 10/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam\n",
            "[CV 1/3; 10/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam;, score=0.647 total time= 2.0min\n",
            "[CV 2/3; 10/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam\n",
            "[CV 2/3; 10/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam;, score=0.644 total time= 1.7min\n",
            "[CV 3/3; 10/10] START alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam\n",
            "[CV 3/3; 10/10] END alpha=0.0001, early_stopping=True, hidden_layer_sizes=(300, 300), max_iter=1000, solver=adam;, score=0.648 total time= 1.7min\n",
            "Val score :  0.6485587798432562\n",
            "Best params :  {'cv': 3, 'error_score': nan, 'estimator__activation': 'relu', 'estimator__alpha': 0.0001, 'estimator__batch_size': 'auto', 'estimator__beta_1': 0.9, 'estimator__beta_2': 0.999, 'estimator__early_stopping': False, 'estimator__epsilon': 1e-08, 'estimator__hidden_layer_sizes': (100,), 'estimator__learning_rate': 'constant', 'estimator__learning_rate_init': 0.001, 'estimator__max_fun': 15000, 'estimator__max_iter': 200, 'estimator__momentum': 0.9, 'estimator__n_iter_no_change': 10, 'estimator__nesterovs_momentum': True, 'estimator__power_t': 0.5, 'estimator__random_state': None, 'estimator__shuffle': True, 'estimator__solver': 'adam', 'estimator__tol': 0.0001, 'estimator__validation_fraction': 0.1, 'estimator__verbose': False, 'estimator__warm_start': False, 'estimator': MLPClassifier(), 'n_jobs': None, 'param_grid': {'hidden_layer_sizes': [1000, 500, (50, 50, 50), (30, 30, 30, 30, 30), 100, 200, 300, (100, 100), (200, 200), (300, 300)], 'early_stopping': [True], 'alpha': [0.0001], 'solver': ['adam'], 'max_iter': [1000]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': 'f1_micro', 'verbose': 10}\n",
            "Retrained model with all training set Test score :  0.6547952229367402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GradBoosting"
      ],
      "metadata": {
        "id": "D_yQdcmWIigA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "1KavPocrImWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbc_params = {'n_estimators':[100, 300, 500, 1000], 'max_depth':[3,5,6]}\n",
        "\n",
        "classifiers_config = [\n",
        "    (GradientBoostingClassifier, gbc_params)\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "id": "z4XkKgnDKNAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0959d74a-79b6-43d7-ba8b-6b70ecf9962d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.ensemble._gb.GradientBoostingClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "[CV 1/3; 1/12] START max_depth=3, n_estimators=100..............................\n",
            "[CV 1/3; 1/12] END max_depth=3, n_estimators=100;, score=0.626 total time=416.6min\n",
            "[CV 2/3; 1/12] START max_depth=3, n_estimators=100..............................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc_params = {'n_estimators':[50,75,100,150, 200, 300]}\n",
        "\n",
        "classifiers_config = [\n",
        "    (RandomForestClassifier, rfc_params),\n",
        "    (SVC,  {})\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "id": "nD8rdlWLJqht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95ea0f6-9db7-494a-ec96-49db4d67a79d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.ensemble._forest.RandomForestClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "[CV 1/3; 1/6] START n_estimators=50.............................................\n",
            "[CV 1/3; 1/6] END ..............n_estimators=50;, score=0.626 total time= 3.8min\n",
            "[CV 2/3; 1/6] START n_estimators=50.............................................\n",
            "[CV 2/3; 1/6] END ..............n_estimators=50;, score=0.622 total time= 3.9min\n",
            "[CV 3/3; 1/6] START n_estimators=50.............................................\n",
            "[CV 3/3; 1/6] END ..............n_estimators=50;, score=0.622 total time= 3.8min\n",
            "[CV 1/3; 2/6] START n_estimators=75.............................................\n",
            "[CV 1/3; 2/6] END ..............n_estimators=75;, score=0.628 total time= 5.9min\n",
            "[CV 2/3; 2/6] START n_estimators=75.............................................\n",
            "[CV 2/3; 2/6] END ..............n_estimators=75;, score=0.626 total time= 5.8min\n",
            "[CV 3/3; 2/6] START n_estimators=75.............................................\n",
            "[CV 3/3; 2/6] END ..............n_estimators=75;, score=0.624 total time= 5.8min\n",
            "[CV 1/3; 3/6] START n_estimators=100............................................\n",
            "[CV 1/3; 3/6] END .............n_estimators=100;, score=0.631 total time= 7.5min\n",
            "[CV 2/3; 3/6] START n_estimators=100............................................\n",
            "[CV 2/3; 3/6] END .............n_estimators=100;, score=0.627 total time= 7.6min\n",
            "[CV 3/3; 3/6] START n_estimators=100............................................\n",
            "[CV 3/3; 3/6] END .............n_estimators=100;, score=0.627 total time= 7.5min\n",
            "[CV 1/3; 4/6] START n_estimators=150............................................\n",
            "[CV 1/3; 4/6] END .............n_estimators=150;, score=0.633 total time=11.7min\n",
            "[CV 2/3; 4/6] START n_estimators=150............................................\n",
            "[CV 2/3; 4/6] END .............n_estimators=150;, score=0.629 total time=11.7min\n",
            "[CV 3/3; 4/6] START n_estimators=150............................................\n",
            "[CV 3/3; 4/6] END .............n_estimators=150;, score=0.630 total time=11.9min\n",
            "[CV 1/3; 5/6] START n_estimators=200............................................\n",
            "[CV 1/3; 5/6] END .............n_estimators=200;, score=0.635 total time=15.5min\n",
            "[CV 2/3; 5/6] START n_estimators=200............................................\n",
            "[CV 2/3; 5/6] END .............n_estimators=200;, score=0.628 total time=15.5min\n",
            "[CV 3/3; 5/6] START n_estimators=200............................................\n",
            "[CV 3/3; 5/6] END .............n_estimators=200;, score=0.631 total time=15.3min\n",
            "[CV 1/3; 6/6] START n_estimators=300............................................\n",
            "[CV 1/3; 6/6] END .............n_estimators=300;, score=0.635 total time=23.0min\n",
            "[CV 2/3; 6/6] START n_estimators=300............................................\n",
            "[CV 2/3; 6/6] END .............n_estimators=300;, score=0.630 total time=23.5min\n",
            "[CV 3/3; 6/6] START n_estimators=300............................................\n",
            "[CV 3/3; 6/6] END .............n_estimators=300;, score=0.631 total time=22.6min\n",
            "Val score :  0.6317938454422293\n",
            "Best params :  {'cv': 3, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'n_jobs': None, 'param_grid': {'n_estimators': [50, 75, 100, 150, 200, 300]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': 'f1_micro', 'verbose': 10}\n",
            "Retrained model with all training set Test score :  0.6353109577627278\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.svm._classes.SVC'> \n",
            "\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3; 1/1] START ............................................................\n",
            "[CV 1/3; 1/1] END ............................., score=0.637 total time=139.8min\n",
            "[CV 2/3; 1/1] START ............................................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc_params = {'n_estimators':[500,750,1000,1500]}\n",
        "\n",
        "classifiers_config = [\n",
        "    (RandomForestClassifier, rfc_params),\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_eivhGrC4Q8",
        "outputId": "cc0cc184-35fb-4c91-ed0f-0cf76abc0f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.ensemble._forest.RandomForestClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "[CV 1/3; 1/4] START n_estimators=500............................................\n",
            "[CV 1/3; 1/4] END .............n_estimators=500;, score=0.637 total time=33.0min\n",
            "[CV 2/3; 1/4] START n_estimators=500............................................\n",
            "[CV 2/3; 1/4] END .............n_estimators=500;, score=0.630 total time=32.8min\n",
            "[CV 3/3; 1/4] START n_estimators=500............................................\n",
            "[CV 3/3; 1/4] END .............n_estimators=500;, score=0.632 total time=32.9min\n",
            "[CV 1/3; 2/4] START n_estimators=750............................................\n",
            "[CV 1/3; 2/4] END .............n_estimators=750;, score=0.636 total time=49.0min\n",
            "[CV 2/3; 2/4] START n_estimators=750............................................\n",
            "[CV 2/3; 2/4] END .............n_estimators=750;, score=0.631 total time=49.2min\n",
            "[CV 3/3; 2/4] START n_estimators=750............................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc_params = {'n_estimators':[100,300, 500,600], 'class_weight': ['balanced']}\n",
        "\n",
        "classifiers_config = [\n",
        "    (RandomForestClassifier, rfc_params),\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox17gK4ZqkAc",
        "outputId": "7e2a436f-2f27-4eb6-d3f4-0011fddebe70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.ensemble._forest.RandomForestClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "[CV 1/3; 1/4] START class_weight=balanced, n_estimators=100.....................\n",
            "[CV 1/3; 1/4] END class_weight=balanced, n_estimators=100;, score=0.631 total time= 5.7min\n",
            "[CV 2/3; 1/4] START class_weight=balanced, n_estimators=100.....................\n",
            "[CV 2/3; 1/4] END class_weight=balanced, n_estimators=100;, score=0.625 total time= 5.7min\n",
            "[CV 3/3; 1/4] START class_weight=balanced, n_estimators=100.....................\n",
            "[CV 3/3; 1/4] END class_weight=balanced, n_estimators=100;, score=0.627 total time= 5.7min\n",
            "[CV 1/3; 2/4] START class_weight=balanced, n_estimators=300.....................\n",
            "[CV 1/3; 2/4] END class_weight=balanced, n_estimators=300;, score=0.632 total time=17.2min\n",
            "[CV 2/3; 2/4] START class_weight=balanced, n_estimators=300.....................\n",
            "[CV 2/3; 2/4] END class_weight=balanced, n_estimators=300;, score=0.629 total time=17.2min\n",
            "[CV 3/3; 2/4] START class_weight=balanced, n_estimators=300.....................\n",
            "[CV 3/3; 2/4] END class_weight=balanced, n_estimators=300;, score=0.629 total time=17.0min\n",
            "[CV 1/3; 3/4] START class_weight=balanced, n_estimators=500.....................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_params = {'n_neighbors': [25,50,150,200,250, 500]}#5, 10, 15, 20, 25, 50, 100,200]}\n",
        "classifiers_config = [\n",
        "    (KNeighborsClassifier, knn_params)\n",
        "]\n",
        "\n",
        "best_trained_models = grid_search(classifiers_config, X_train, y_train, X_test, y_test, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRmWIeeVtFJK",
        "outputId": "4686ccbf-1321-44b2-e3e6-6fa5582598d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search for model :   <class 'sklearn.neighbors._classification.KNeighborsClassifier'> \n",
            "\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "[CV 1/3; 1/6] START n_neighbors=25..............................................\n",
            "[CV 1/3; 1/6] END ...............n_neighbors=25;, score=0.604 total time= 2.1min\n",
            "[CV 2/3; 1/6] START n_neighbors=25..............................................\n",
            "[CV 2/3; 1/6] END ...............n_neighbors=25;, score=0.602 total time= 2.0min\n",
            "[CV 3/3; 1/6] START n_neighbors=25..............................................\n",
            "[CV 3/3; 1/6] END ...............n_neighbors=25;, score=0.604 total time= 2.1min\n",
            "[CV 1/3; 2/6] START n_neighbors=50..............................................\n",
            "[CV 1/3; 2/6] END ...............n_neighbors=50;, score=0.605 total time= 2.1min\n",
            "[CV 2/3; 2/6] START n_neighbors=50..............................................\n",
            "[CV 2/3; 2/6] END ...............n_neighbors=50;, score=0.603 total time= 2.1min\n",
            "[CV 3/3; 2/6] START n_neighbors=50..............................................\n",
            "[CV 3/3; 2/6] END ...............n_neighbors=50;, score=0.605 total time= 2.0min\n",
            "[CV 1/3; 3/6] START n_neighbors=150.............................................\n",
            "[CV 1/3; 3/6] END ..............n_neighbors=150;, score=0.600 total time= 2.1min\n",
            "[CV 2/3; 3/6] START n_neighbors=150.............................................\n",
            "[CV 2/3; 3/6] END ..............n_neighbors=150;, score=0.598 total time= 2.1min\n",
            "[CV 3/3; 3/6] START n_neighbors=150.............................................\n",
            "[CV 3/3; 3/6] END ..............n_neighbors=150;, score=0.597 total time= 2.0min\n",
            "[CV 1/3; 4/6] START n_neighbors=200.............................................\n",
            "[CV 1/3; 4/6] END ..............n_neighbors=200;, score=0.597 total time= 2.1min\n",
            "[CV 2/3; 4/6] START n_neighbors=200.............................................\n",
            "[CV 2/3; 4/6] END ..............n_neighbors=200;, score=0.595 total time= 2.0min\n",
            "[CV 3/3; 4/6] START n_neighbors=200.............................................\n",
            "[CV 3/3; 4/6] END ..............n_neighbors=200;, score=0.595 total time= 2.0min\n",
            "[CV 1/3; 5/6] START n_neighbors=250.............................................\n",
            "[CV 1/3; 5/6] END ..............n_neighbors=250;, score=0.594 total time= 2.1min\n",
            "[CV 2/3; 5/6] START n_neighbors=250.............................................\n",
            "[CV 2/3; 5/6] END ..............n_neighbors=250;, score=0.593 total time= 2.0min\n",
            "[CV 3/3; 5/6] START n_neighbors=250.............................................\n",
            "[CV 3/3; 5/6] END ..............n_neighbors=250;, score=0.593 total time= 2.1min\n",
            "[CV 1/3; 6/6] START n_neighbors=500.............................................\n",
            "[CV 1/3; 6/6] END ..............n_neighbors=500;, score=0.586 total time= 2.1min\n",
            "[CV 2/3; 6/6] START n_neighbors=500.............................................\n",
            "[CV 2/3; 6/6] END ..............n_neighbors=500;, score=0.586 total time= 2.1min\n",
            "[CV 3/3; 6/6] START n_neighbors=500.............................................\n",
            "[CV 3/3; 6/6] END ..............n_neighbors=500;, score=0.584 total time= 2.1min\n",
            "Val score :  0.604499335575707\n",
            "Best params :  {'cv': 3, 'error_score': nan, 'estimator__algorithm': 'auto', 'estimator__leaf_size': 30, 'estimator__metric': 'minkowski', 'estimator__metric_params': None, 'estimator__n_jobs': None, 'estimator__n_neighbors': 5, 'estimator__p': 2, 'estimator__weights': 'uniform', 'estimator': KNeighborsClassifier(), 'n_jobs': None, 'param_grid': {'n_neighbors': [25, 50, 150, 200, 250, 500]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': 'f1_micro', 'verbose': 10}\n",
            "Retrained model with all training set Test score :  0.6121092998910419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report Generation"
      ],
      "metadata": {
        "id": "B2R3ByrXaY_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "def generate_predictions_report(best_trained_models, data_to_predict, y_encoder) :\n",
        "  X_to_predict, Ids = data_to_predict\n",
        "  for idx,model in enumerate(best_trained_models) :\n",
        "    \n",
        "    predictions = model.predict(X_to_predict)\n",
        "    predictions = decode_predictions(predictions.reshape(-1,1), y_encoder).reshape(len(predictions))\n",
        "    report = pd.DataFrame({'Id': Ids, 'Predicted' : predictions })\n",
        "\n",
        "    report.to_csv(f'{idx}_report.csv', index = False)\n",
        "    files.download(f'{idx}_report.csv')\n",
        "\n",
        "generate_predictions_report(best_trained_models, data_to_predict, y_encoder)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "rCQi6EOfhDDk",
        "outputId": "dde7d31d-4bb4-4f94-b909-bb7beeed398a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6fcc45c3-1c4f-4aab-bd7f-edae17c673b9\", \"0_report.csv\", 1081612)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}